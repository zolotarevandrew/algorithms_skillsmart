1) Время асинхронного перехода с первого шага онбординга на второй

На первом шаге запускается процесс, который заполняет досье клиента из внешних систем, чтобы продолжить дальше - нужно подождать заполнения и получить ответ асинхронно, (камунда дойдет до определенного шага).
Поскольку мы явно завязаны на внешние системы, и границы стабильности из за этого явно расширяются.

Здесь можно предложить следующий вариант
TRIPWIRE(10,30) секунд - контролировать начинаем, только если пользователь прождал более 10 секунд, и максимум это 30.
При этом выставляем жесткие таймауты на работу с внешними системами, чтобы в это время уложиться (на самом деле уже реализовали эти таймауты).
Да здесь могут быть ложные срабатывания - внешняя система дала сбой для ряда пользователей, а потом вернулась в нормальное состояние.
Из за таких ситуаций добавим предусловие в разрезах конкретной страны (разные интеграции на разную страну) 

STABLE(90, 100) - процент запросов, которые уложились в интервал до 10 секунд.
По сути 90% перцентиль.
Такое позволит избавится от ложных срабатываний, описанных выше.

На досуге подумаю еще над этим свойством, оно достаточно сложное и требует более детальной проработки.

2) Время перехода от последнего законченного блока к вызову нового в камунда
(На определенные важные процессы)

Когда камунда тупит, она может долго создавать джобы и время перехода, между некоторыми шагами в процессе может увеличиватся.
STRONG(0,2) время в секундах перехода между блоками. Если больше, то надежность системы начала сильно скатываться.

Предусловием будет TRIPWIRE (0.5, 2) - будем начинать контролировать если время перехода превысило 0,5 секунд.
Все же может быть волнообразная нагрузка и 0,5 секунд - это допустимо.

3) скорость доставки джобы от camunda до появления в нашем коде 
(На определенные важные процессы)

джоба создалась в камунде, а затем мы подтянули ее на исполнение

STRONG(0,2)

Для получения джоб используется лонг поллинг в несколько потоков, если при получении джобы разница времени создания и текущее время более 2 секунд, 
значит имеем серьезные проблемы с надежностью камунды.

4) Время перехода между обычными шагами онбординга (не асинхронными, как в пункте 1)

Время от клика пользователя «далее» - до появления следующего шага на фронтенде

STABLE(0,1) - все же может быть усиленная нагрузка на базу и сетевые задержки, 

Но возможно стоит начать с STRONG(0,0,5) - как более жесткий критерий, чтобы узнать даже о сетевых задержках и нагрузке на базу.

5) Время ответа на запрос от базы данных для онбординга
(покрываем случаи, когда есть не оптимизированный запрос)

STRONG(0,1) - если какой-то запрос ушел за 1 секунду выполнения, то система явна не стабильна.

Дополнительно, можно сделать контроль всех предыдуших метрик, с учетом количества запущенных онбординг процессов за одну последнюю минуту
Система явно может не выдержать сильный наплыв пользователей. 
Предусловие - TRIPWIRE(10,1000) - здесь сильный разброс, если набежало от 10 до 1000 клиентов за минуту. 
(проще сделать от 10 до бесконечности, но 1000 это совсем нереальная цифра сейчас даже, зависит от маркетинга, столько клиентов разом очень маловероятно)

Я думаю, что можно усилить инварианты в:
- свойство 2, до 0.2-0.3 секунд, если камунда будет хостится рядом с нашей инфраструктурой (в районе 300-500км) - минус сетевые задержки.
- для свойства 1, процент запросов, которые уложились в интервал до 10 секунд, можно повысить до 95, но это надо прямо исследовать, не могу дать гарантии.

По поводу характеристик скорости восстановления - это сложно описать на данный момент, поскольку для совсем простых характеристик могут быть частые ложные срабатывания.
Больше похоже на нечто статистическое с учетом времени (как было описано в теории).


Итого - очень интересная система формализации, как раз хотел в ближайшие 3 месяца заниматься метриками системы, возьму себе как основной инструмент
на вооружение.




